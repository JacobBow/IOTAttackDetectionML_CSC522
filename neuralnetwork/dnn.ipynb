{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/1s/tyt3m2l12dz6s028_blqch7r0000gn/T/ipykernel_66854/1971013312.py:3: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import gc\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, BatchNormalization, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import sys\n",
    "sys.path.append( '../util' )\n",
    "import util as util"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DNN with 2 classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing datasets.....\n",
      "Processing training and test data....\n",
      "Finished processing training and test data\n",
      "Mapping labels to two classes.....\n",
      "Data import and processing complete....\n",
      "Epoch 1/100\n",
      "\u001b[1m113583/113583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m540s\u001b[0m 5ms/step - accuracy: 0.9894 - loss: 0.0283 - val_accuracy: 0.9937 - val_loss: 0.0146\n",
      "Epoch 2/100\n",
      "\u001b[1m113583/113583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m554s\u001b[0m 5ms/step - accuracy: 0.9935 - loss: 0.0150 - val_accuracy: 0.9940 - val_loss: 0.0139\n",
      "Epoch 3/100\n",
      "\u001b[1m113583/113583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m487s\u001b[0m 4ms/step - accuracy: 0.9937 - loss: 0.0145 - val_accuracy: 0.9941 - val_loss: 0.0135\n",
      "Epoch 4/100\n",
      "\u001b[1m113583/113583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3796s\u001b[0m 33ms/step - accuracy: 0.9938 - loss: 0.0142 - val_accuracy: 0.9942 - val_loss: 0.0135\n",
      "Epoch 5/100\n",
      "\u001b[1m113583/113583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1715s\u001b[0m 15ms/step - accuracy: 0.9939 - loss: 0.0140 - val_accuracy: 0.9939 - val_loss: 0.0143\n",
      "Epoch 6/100\n",
      "\u001b[1m113583/113583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2614s\u001b[0m 23ms/step - accuracy: 0.9939 - loss: 0.0139 - val_accuracy: 0.9943 - val_loss: 0.0134\n",
      "Epoch 7/100\n",
      "\u001b[1m113583/113583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m532s\u001b[0m 5ms/step - accuracy: 0.9940 - loss: 0.0138 - val_accuracy: 0.9942 - val_loss: 0.0135\n",
      "Epoch 8/100\n",
      "\u001b[1m 23499/113583\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6:38\u001b[0m 4ms/step - accuracy: 0.9940 - loss: 0.0137"
     ]
    }
   ],
   "source": [
    "\n",
    "def create_binary_classification_model(input_shape):\n",
    "    inputs = Input(shape=(input_shape,))\n",
    "    x = Dense(128, activation='relu')(inputs)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(64, activation='relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    outputs = Dense(1, activation='sigmoid')(x)\n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    model.compile(optimizer=Adam(learning_rate=0.001),\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "train, test = util.import_dataset(2,\"dnn\")\n",
    "\n",
    "\n",
    "\n",
    "y_train = train[util.y_column]\n",
    "y_test = test[util.y_column]\n",
    "\n",
    "X_train = train.drop(util.y_column, axis=1)\n",
    "X_test = test.drop(util.y_column, axis=1)\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "y_test_encoded = label_encoder.transform(y_test)\n",
    "\n",
    "del train,test,y_train,y_test\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model = create_binary_classification_model(len(util.X_columns))\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "#https://keras.io/api/models/model_training_apis/\n",
    "history = model.fit(x=X_train, y=y_train_encoded,\n",
    "                    validation_split=0.2, epochs=100, \n",
    "                    batch_size=256, callbacks=[early_stopping])\n",
    "\n",
    "\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test_encoded, verbose=2)\n",
    "print(f'Test accuracy: {test_acc}, Test loss: {test_loss}')\n",
    "del X_train,X_test,y_train,y_test"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
